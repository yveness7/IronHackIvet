{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZharljNsul_m",
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Data-Transformation:-Combining-and-Structuring-Data\" data-toc-modified-id=\"Data-Transformation:-Combining-and-Structuring-Data-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Data Transformation: Combining and Structuring Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#Combining-Data\" data-toc-modified-id=\"Combining-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Combining Data</a></span><ul class=\"toc-item\"><li><span><a href=\"#concat\" data-toc-modified-id=\"concat-1.1.1\"><span class=\"toc-item-num\">1.1.1&nbsp;&nbsp;</span><code>concat</code></a></span><ul class=\"toc-item\"><li><span><a href=\"#axis=0\" data-toc-modified-id=\"axis=0-1.1.1.1\"><span class=\"toc-item-num\">1.1.1.1&nbsp;&nbsp;</span><code>axis=0</code></a></span></li><li><span><a href=\"#axis=1\" data-toc-modified-id=\"axis=1-1.1.1.2\"><span class=\"toc-item-num\">1.1.1.2&nbsp;&nbsp;</span><code>axis=1</code></a></span></li><li><span><a href=\"#join=&quot;inner&quot;\" data-toc-modified-id=\"join=&quot;inner&quot;-1.1.1.3\"><span class=\"toc-item-num\">1.1.1.3&nbsp;&nbsp;</span><code>join=\"inner\"</code></a></span></li></ul></li><li><span><a href=\"#merge\" data-toc-modified-id=\"merge-1.1.2\"><span class=\"toc-item-num\">1.1.2&nbsp;&nbsp;</span><code>merge</code></a></span></li><li><span><a href=\"#join\" data-toc-modified-id=\"join-1.1.3\"><span class=\"toc-item-num\">1.1.3&nbsp;&nbsp;</span><code>join</code></a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1.1.4\"><span class=\"toc-item-num\">1.1.4&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-1.1.5\"><span class=\"toc-item-num\">1.1.5&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li></ul></li><li><span><a href=\"#Structuring-Data-with-Pivot,-Stack/Unstack,-and-Melt\" data-toc-modified-id=\"Structuring-Data-with-Pivot,-Stack/Unstack,-and-Melt-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Structuring Data with Pivot, Stack/Unstack, and Melt</a></span><ul class=\"toc-item\"><li><span><a href=\"#Pivot\" data-toc-modified-id=\"Pivot-1.2.1\"><span class=\"toc-item-num\">1.2.1&nbsp;&nbsp;</span>Pivot</a></span></li><li><span><a href=\"#Stack-and-Unstack\" data-toc-modified-id=\"Stack-and-Unstack-1.2.2\"><span class=\"toc-item-num\">1.2.2&nbsp;&nbsp;</span>Stack and Unstack</a></span></li><li><span><a href=\"#Melt\" data-toc-modified-id=\"Melt-1.2.3\"><span class=\"toc-item-num\">1.2.3&nbsp;&nbsp;</span>Melt</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1.2.4\"><span class=\"toc-item-num\">1.2.4&nbsp;&nbsp;</span>Summary</a></span></li><li><span><a href=\"#ðŸ’¡-Check-for-understanding\" data-toc-modified-id=\"ðŸ’¡-Check-for-understanding-1.2.5\"><span class=\"toc-item-num\">1.2.5&nbsp;&nbsp;</span>ðŸ’¡ Check for understanding</a></span></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DELJNOmjul_r"
   },
   "source": [
    "# Data Transformation: Combining and Structuring Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CmkUZc6Uul_r"
   },
   "source": [
    "## Combining Data\n",
    "\n",
    "When working with data, you often encounter situations where you need to combine or merge multiple datasets to gain more insights or perform further analysis.\n",
    "\n",
    "Pandas provides functions for [combining different data sets](http://pandas.pydata.org/pandas-docs/stable/merging.html) based on [relational algebra](https://en.wikipedia.org/wiki/Relational_algebra): `join`, `merge` and `concat`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZQ6w3WTLul_s"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# DataFrame 1: Sales information\n",
    "df_sales = pd.DataFrame({\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-04'],\n",
    "    'Product': ['A', 'B', 'C', 'D'],\n",
    "    'Quantity_Sold': [100, 200, 150, 120]\n",
    "})\n",
    "\n",
    "# DataFrame 2: Revenue information\n",
    "df_revenue = pd.DataFrame({\n",
    "    'Date': ['2023-01-01', '2023-01-02', '2023-01-03', '2023-01-05'],\n",
    "    'Revenue': [1000, 1500, 1200, 800]\n",
    "})\n",
    "\n",
    "# DataFrame 3: Costs information\n",
    "df_costs = pd.DataFrame({\n",
    "    'Date': ['2023-01-01', '2023-01-03', '2023-01-04', '2023-01-05'],\n",
    "    'Costs': [500, 700, 600, 400]\n",
    "})\n",
    "\n",
    "# DataFrame 1: Sales information next 4 months\n",
    "df_sales_2 = pd.DataFrame({\n",
    "    'Date': ['2023-01-05', '2023-01-06', '2023-01-07', '2023-01-08'],\n",
    "    'Product': ['A', 'B', 'C', 'D'],\n",
    "    'Quantity_Sold': [100, 200, 150, 120]\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2um5_QD9ul_s"
   },
   "source": [
    "### `concat`\n",
    "\n",
    "- `concat` is usually used when you want to combine two or more DataFrames vertically or horizontally.\n",
    "- It is commonly used when you have data split across multiple files or sources and want to stack them together to create a larger dataset.\n",
    "- Vertical concatenation is used when you want to add more rows to an existing DataFrame.\n",
    "- Horizontal concatenation is used when you want to add more columns to an existing DataFrame.\n",
    "- Example: combining monthly or yearly sales data: Suppose you have sales data for a retail store split across multiple files, where each file contains sales data for a specific month or year. You can use concat to vertically stack these DataFrames and create a single DataFrame containing the complete sales data for all months or years."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u29jqUJ8ul_s"
   },
   "source": [
    "`pd.concat` is used to concatenate multiple DataFrames.\n",
    "- The `axis` parameter determines the axis along which the DataFrames will be stacked. `axis=0` (the default) stacks the DataFrames vertically (along rows), while `axis=1` stacks them horizontally (along columns)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CM_1JeCEul_s"
   },
   "source": [
    "#### `axis=0`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "161xLJIvul_t"
   },
   "outputs": [],
   "source": [
    "# Concatenate the sales, and sales_2 vertically (along rows)\n",
    "pd.concat([df_sales, df_sales_2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HjzEzHDiul_t"
   },
   "outputs": [],
   "source": [
    "# Concatenate the sales, revenue, and costs DataFrames vertically (along rows)\n",
    "pd.concat([df_sales, df_revenue, df_costs], axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tKdzgLbAul_t"
   },
   "source": [
    "#### `axis=1`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3RC7tJecul_t"
   },
   "outputs": [],
   "source": [
    "# Concatenate the sales, revenue, and costs DataFrames horizontally (along columns)\n",
    "pd.concat([df_sales, df_revenue, df_costs], axis=1) # by default is outer, takes the union"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgWICYCQul_u"
   },
   "source": [
    "#### `join=\"inner\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3HXQDklul_u"
   },
   "source": [
    "- `Join` Parameter:\n",
    "    - The `join` parameter is used to specify how to handle the overlapping columns during concatenation.\n",
    "    - By default (`join='outer'`), all columns from all DataFrames are included in the result, and missing values are filled with NaN.\n",
    "    - If `join='inner'`, only the overlapping columns are included in the result, and non-overlapping columns are excluded.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xvssydahul_u"
   },
   "outputs": [],
   "source": [
    "pd.concat([df_sales, df_revenue, df_costs], axis=0, join=\"inner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esfnleIIul_u"
   },
   "source": [
    "### `merge`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zNqBZeipul_u"
   },
   "source": [
    "Merge is used to combine DataFrames based on a common column. By default, `merge` performs an *inner join*, where only the matching rows between the DataFrames are included in the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zZgz7_gWul_u"
   },
   "outputs": [],
   "source": [
    "df_revenue.Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NJQX1e0aul_u"
   },
   "outputs": [],
   "source": [
    "# Merge the sales and revenue DataFrames on the 'Date' column (inner join)\n",
    "# Only rows with a common value in the 'Date' column, present in both DataFrames, are included in the merged result.\n",
    "pd.merge(df_sales, df_revenue, on='Date')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ysB5YPxOul_u"
   },
   "source": [
    "If you want to perform an outer join, where all rows from both DataFrames are included, you can use `how='outer'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b1wciD4vul_u"
   },
   "outputs": [],
   "source": [
    "# Merge the sales and revenue DataFrames on the 'Date' column (outer join)\n",
    "pd.merge(df_sales, df_revenue, on='Date', how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B3aHV0ojul_v"
   },
   "source": [
    "If you want to include all rows from the left DataFrame and only the matching rows from the right DataFrame, you can use `how='left'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7aaRNG7sul_v"
   },
   "outputs": [],
   "source": [
    "# Merge the sales and revenue DataFrames on the 'Date' column (left join)\n",
    "pd.merge(df_sales, df_revenue, on='Date', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SaSbSaL9ul_v"
   },
   "source": [
    "Similarly, if you want to include all rows from the right DataFrame and only the matching rows from the left DataFrame, you can use `how='right'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W04N0-u5ul_v"
   },
   "outputs": [],
   "source": [
    "# Merge the sales and revenue DataFrames on the 'Date' column (right join)\n",
    "pd.merge(df_sales, df_revenue, on='Date', how='right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gxtToCOzul_v"
   },
   "source": [
    "In these examples, we had the same column ('Date') in both DataFrames, but this is not always the case. To perform such joins, we use the `left_on` and `right_on` parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6hcVA5dQul_v"
   },
   "source": [
    "`df1.merge(df2, left_on='col_1', right_on='col_2', how='inner')`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N3RRjWltul_v"
   },
   "source": [
    "### `join`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nGSmpslaul_v"
   },
   "source": [
    "`join()` works similarly to `merge()`. It is also used to combine DataFrames. However, there are some differences between the two:\n",
    "\n",
    "1. **Method of Combination:**\n",
    "   - `join()`: Combines DataFrames **based on their indexes**. It uses the index as the key to align the rows.\n",
    "   - `merge()`: Combines DataFrames **based on the values in specified columns**. It can use one or more columns as the keys to align the rows.\n",
    "\n",
    "2. **Default Behavior:**\n",
    "   - `join()`: By default, performs a left join, keeping all rows from the left DataFrame and filling missing values with NaN from the right DataFrame.\n",
    "   - `merge()`: By default, performs an inner join, keeping only the rows with matching values in both DataFrames.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C_RRsYbYul_v"
   },
   "source": [
    "First, we set the 'Date' column as the index for all three DataFrames, as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qc_Svgaiul_v"
   },
   "outputs": [],
   "source": [
    "df_sales.set_index('Date', inplace=True)\n",
    "df_revenue.set_index('Date', inplace=True)\n",
    "df_costs.set_index('Date', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p-67XB_gul_w"
   },
   "source": [
    "Next, we use the `join()` method on `df_sales` to merge it with `df_revenue` and `df_costs`. By default, `join()` uses the 'Date' column as the key to merge the DataFrames.\n",
    "\n",
    "The resulting df_combined DataFrame will contain all rows from df_sales along with corresponding revenue and costs information, where available. If there is no data for a specific date in either df_revenue or df_costs, the corresponding values will be filled with NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zl5wUEzhul_w"
   },
   "outputs": [],
   "source": [
    "# By default is a Left Join: Keep all rows from the left DataFrame and fill missing values with NaN from the right DataFrame.\n",
    "\n",
    "df_sales.join([df_revenue, df_costs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cIui12A3ul_w"
   },
   "outputs": [],
   "source": [
    "# Inner Join: Only include rows with matching 'Date' values in both DataFrames.\n",
    "df_sales.join([df_revenue, df_costs], how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BceBVKW_ul_w"
   },
   "outputs": [],
   "source": [
    "# Outer Join: Include all rows from both DataFrames and fill missing values with NaN where data is not available.\n",
    "df_sales.join([df_revenue, df_costs],how='outer')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uWmYZpkaul_w"
   },
   "source": [
    "### Summary\n",
    "\n",
    "- `concat` is used to combine two or more DataFrames vertically or horizontally. It's often used when data is split across multiple files and you want to create a larger dataset.\n",
    "  - Vertical concatenation adds more rows to a DataFrame.\n",
    "  - Horizontal concatenation adds more columns to a DataFrame.\n",
    "  - `pd.concat` is used with the `axis` parameter determining the axis along which the DataFrames will be stacked (`axis=0` for rows and `axis=1` for columns).\n",
    "  - The `join` parameter determines how to handle overlapping columns during concatenation. `join='outer'` includes all columns and fills missing values with NaN, while `join='inner'` includes only overlapping columns.\n",
    "- `merge` is used to combine DataFrames based on a common column.\n",
    "  - By default, `merge` performs an inner join, including only the matching rows between the DataFrames.\n",
    "  - `how='outer'` performs an outer join, including all rows from both DataFrames.\n",
    "  - `how='left'` performs a left join, including all rows from the left DataFrame and only matching rows from the right.\n",
    "  - `how='right'` performs a right join, including all rows from the right DataFrame and only matching rows from the left.\n",
    "  - If the columns to join on don't have the same name, `left_on` and `right_on` parameters are used.\n",
    "- `join` is used to combine DataFrames based on their indexes.\n",
    "  - By default, `join` performs a left join.\n",
    "  - The DataFrame's index can be set using `set_index` and then `join` can be used to merge on this index.\n",
    "  - Different types of joins (inner, outer) can be performed using the `how` parameter in the `join` function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T83qToc9ul_w"
   },
   "source": [
    "### ðŸ’¡ Check for understanding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O5UGyOrdul_w"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Dataset 1: Student information\n",
    "df_students = pd.DataFrame({\n",
    "    'StudentID': ['S1', 'S2', 'S3', 'S4'],\n",
    "    'Name': ['Alice', 'Bob', 'Charlie', 'Dave'],\n",
    "    'Major': ['Physics', 'Mathematics', 'Chemistry', 'Biology']\n",
    "})\n",
    "\n",
    "# Create df_students_2 DataFrame\n",
    "df_students_2 = pd.DataFrame({\n",
    "    'StudentID': ['S5', 'S6'],\n",
    "    'Name': ['Eve', 'Frank'],\n",
    "    'Major': ['English', 'Computer Science']\n",
    "})\n",
    "\n",
    "# Dataset 2: Course enrollment information\n",
    "df_courses = pd.DataFrame({\n",
    "    'StudentID': ['S1', 'S2', 'S3', 'S5'],\n",
    "    'Course': ['Physics 101', 'Mathematics 101', 'Chemistry 101', 'Biology 101']\n",
    "})\n",
    "\n",
    "# Dataset 3: Student grades\n",
    "df_grades = pd.DataFrame({\n",
    "    'StudentID': ['S1', 'S3', 'S4', 'S6'],\n",
    "    'Grade': ['A', 'B', 'A', 'C']\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hS1wNzchul_x"
   },
   "source": [
    "1. Create a new DataFrame that contains the information from both `df_students` and `df_students_2`.\n",
    "\n",
    "2. Merge `df_students` and `df_courses` on the 'StudentID' column. Try all four types of merges (inner, outer, left, and right) and observe the differences.\n",
    "\n",
    "3. Set 'StudentID' as the index for `df_students`, `df_courses`, and `df_grades`. Then use `df_students.join` to combine all three datasets. Try different types of joins (inner, outer) and observe the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer goes here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XRSh6LOHul_y"
   },
   "source": [
    "## Structuring Data with Pivot, Stack/Unstack, and Melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a-3XT1zzul_y"
   },
   "source": [
    "These methods are useful for restructuring, aggregating, and reshaping data to better analyze and visualize it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UVAvZBmTul_y"
   },
   "source": [
    "### Pivot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O0x1eXt_ul_y"
   },
   "source": [
    "- Pivot is used to create a new derived table from another one.\n",
    "- Allows us to reshape a DataFrame based on column values.\n",
    "- Converts unique values from one column into multiple columns."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "USHSpFV_ul_y"
   },
   "source": [
    "![](https://github.com/data-bootcamp-v4/lessons/blob/main/img/pivot.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "t-eYQaNnul_y"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load Chipotle dataset from an online source\n",
    "url = 'https://raw.githubusercontent.com/data-bootcamp-v4/data/main/worldstats.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "K81upZ8_ul_y"
   },
   "outputs": [],
   "source": [
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "k9DBiPgdul_z"
   },
   "outputs": [],
   "source": [
    "# Pivot the DataFrame to see the GDP based on the country and year\n",
    "pivot_df = df.pivot_table(index='country', columns='year', values=['GDP'], aggfunc='sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fyVoCBuaul_z"
   },
   "outputs": [],
   "source": [
    "pivot_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fns9j8Sjul_0"
   },
   "source": [
    "###Â Stack and Unstack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uKqDsu7rul_0"
   },
   "source": [
    "In pandas, `stack()` and `unstack()` are two methods used to transform data between \"wide\" and \"long\" formats in a DataFrame.\n",
    "\n",
    "- `stack()`: This method \"stacks\" the data, converting the **columns into rows**, and results in a multi-level index. It is useful when you have a DataFrame with multiple columns representing similar data, and you want to combine them into a single column.\n",
    "\n",
    "- `unstack()`: This method does the opposite of `stack()`. It \"unstacks\" the data, converting the **index back into columns**, and results in a more \"wide\" format. It is useful when you have a DataFrame with multi-level index and you want to separate the levels into separate columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a5IOK8c0ul_0"
   },
   "source": [
    "![](https://github.com/data-bootcamp-v4/lessons/blob/main/img/stack.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rxe3gjk5ul_0"
   },
   "outputs": [],
   "source": [
    "# Create a multi-index DataFrame using set_index with 'country' and 'year' as the index columns\n",
    "df_multiindex = df.set_index(['country', 'year'])\n",
    "df_multiindex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8OlhxWNeul_0"
   },
   "outputs": [],
   "source": [
    "# Stack the DataFrame to convert columns into rows and create a Series\n",
    "stacked_data = df_multiindex.stack()\n",
    "stacked_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JyDXPEaLul_0"
   },
   "outputs": [],
   "source": [
    "# Unstack the Series back into a DataFrame with the 'year' level as columns\n",
    "unstacked_data = stacked_data.unstack('year')\n",
    "\n",
    "unstacked_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HvJFWc9Hul_1"
   },
   "source": [
    "### Melt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4sctzSq1ul_1"
   },
   "source": [
    "The `melt()` function in pandas is used to transform a DataFrame from a **wide format to a long format**, which is often more suitable for certain data analysis tasks. In the wide format, each row represents a unique observation, and each column represents a different variable. However, in the long format, multiple rows may represent the same observation, and a new column is introduced to distinguish between the different variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P0BF5UUMul_1"
   },
   "source": [
    "![](https://github.com/data-bootcamp-v4/lessons/blob/main/img/melt.png?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WMVHDgIYul_1"
   },
   "outputs": [],
   "source": [
    "# Melt the DataFrame, keeping 'country' and 'year' as identifier variables, and 'Population' and 'GDP' as value variables\n",
    "melted_data = pd.melt(df, id_vars=['country', 'year'], value_vars=['Population', 'GDP'], var_name='Indicator', value_name='Value')\n",
    "melted_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RE9YvEe6ul_1"
   },
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7yERr76hul_1"
   },
   "source": [
    "- `pivot` is used to create a new derived table from an existing one by reshaping a DataFrame based on column values and converting unique values from one column into multiple columns.\n",
    "- `stack` and `unstack` are used to transform data between \"wide\" and \"long\" formats.\n",
    "  - `stack` converts columns into rows, leading to a multi-level index. It's useful when multiple columns represent similar data that you want to combine into a single column.\n",
    "  - `unstack` does the opposite of `stack`, converting the index back into columns and leading to a more \"wide\" format. It's useful when a DataFrame has a multi-level index that you want to separate into different columns.\n",
    "- `melt` transforms a DataFrame from a wide format to a long format. It's useful for certain data analysis tasks where each row represents a unique observation in the wide format, but in the long format, multiple rows represent the same observation, and a new column is introduced to distinguish between different variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XG913Gotul_1"
   },
   "source": [
    "### ðŸ’¡ Check for understanding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k1xgA7hpul_1"
   },
   "source": [
    "You are given a DataFrame with sales data for a company. The DataFrame contains information about the sales of various products in different regions. Create a summary of the total sales for each product in each region.\n",
    "\n",
    "\n",
    "Dataset:\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'Product': ['A', 'B', 'C', 'A', 'B', 'C', 'A', 'B', 'C'],\n",
    "    'Region': ['North', 'North', 'North', 'South', 'South', 'South', 'East', 'East', 'East'],\n",
    "    'Sales': [100, 150, 200, 120, 180, 240, 80, 110, 160]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "```\n",
    "\n",
    "Expected output:\n",
    "\n",
    "```python\n",
    "Region   East  North  South\n",
    "\n",
    "Product                    \n",
    "\n",
    "A          80    100    120\n",
    "\n",
    "B         110    150    180\n",
    "\n",
    "C         160    200    240\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A7UsQtbOul_1"
   },
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "537.273px",
    "left": "304.999px",
    "top": "110.824px",
    "width": "426.996px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
