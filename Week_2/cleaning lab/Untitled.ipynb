{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51eed2cc",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 15\u001b[0m\n\u001b[1;32m     11\u001b[0m pop_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(factbook_pop)\n\u001b[1;32m     12\u001b[0m obesity_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(factbook_obesity)\n\u001b[0;32m---> 15\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(pop_df, obesity_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m merged_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m rk \u001b[38;5;241m=\u001b[39m cast(Hashable, rk)\n\u001b[1;32m   1161\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m rk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1162\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(rk))\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1164\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     right_keys\u001b[38;5;241m.\u001b[39mappend(right\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country'"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#def analyze(factbook_pop: str, factbook_obesity: str) -> pd.DataFrame:\n",
    "\n",
    "factbook_pop = 'https://raw.githubusercontent.com/yveness7/IronHackIvet/main/Week_2/assessment2/c2119.csv'\n",
    "factbook_obesity = 'https://raw.githubusercontent.com/yveness7/IronHackIvet/main/Week_2/assessment2/c2228.csv'\n",
    "data1 = pd.read_csv(url1)\n",
    "data2 = pd.read_csv(url2)\n",
    "\n",
    "\n",
    "pop_df = pd.read_csv(factbook_pop)\n",
    "obesity_df = pd.read_csv(factbook_obesity)\n",
    "\n",
    "    \n",
    "merged_df = pd.merge(pop_df, obesity_df, on='Country')\n",
    "merged_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "166f3829",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'rename'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m factbook_pop\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPos\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPopulation\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      2\u001b[0m factbook_obesity\u001b[38;5;241m.\u001b[39mrename(columns \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPos\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIndex\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mName\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValue\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mObesity Rate\u001b[39m\u001b[38;5;124m'\u001b[39m}, inplace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'rename'"
     ]
    }
   ],
   "source": [
    "factbook_pop.rename(columns={'Pos': 'Index', 'Name': 'Country', 'Value': 'Population'}, inplace=True)\n",
    "factbook_obesity.rename(columns={'Pos': 'Index', 'Name': 'Country', 'Value': 'Obesity Rate'}, inplace=True)\n",
    "\n",
    "factbook_pop.drop(columns=['Index'], inplace=True)\n",
    "factbook_obesity.drop(columns=['Index'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "513125b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Index', 'Country', 'Obesity Rate'], dtype='object')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "obesity_df.rename(columns = {'Pos':'Index','Name':'Country','Value':'Obesity Rate'}, inplace=True)\n",
    "obesity_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "debc15f4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Country'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge(pop_df, obesity_df, on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      2\u001b[0m merged_df\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@Substitution\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mleft : DataFrame or named Series\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;129m@Appender\u001b[39m(_merge_doc, indents\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[38;5;241m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[38;5;241m=\u001b[39mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[38;5;241m=\u001b[39mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[38;5;241m=\u001b[39mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[38;5;241m=\u001b[39mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[38;5;241m=\u001b[39mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[38;5;241m=\u001b[39mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[38;5;241m=\u001b[39msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[38;5;241m=\u001b[39msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[38;5;241m=\u001b[39mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[38;5;241m=\u001b[39mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result(copy\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cross \u001b[38;5;241m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[38;5;66;03m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[38;5;66;03m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[38;5;66;03m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/reshape/merge.py:1179\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1175\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lk \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1176\u001b[0m     \u001b[38;5;66;03m# Then we're either Hashable or a wrong-length arraylike,\u001b[39;00m\n\u001b[1;32m   1177\u001b[0m     \u001b[38;5;66;03m#  the latter of which will raise\u001b[39;00m\n\u001b[1;32m   1178\u001b[0m     lk \u001b[38;5;241m=\u001b[39m cast(Hashable, lk)\n\u001b[0;32m-> 1179\u001b[0m     left_keys\u001b[38;5;241m.\u001b[39mappend(left\u001b[38;5;241m.\u001b[39m_get_label_or_level_values(lk))\n\u001b[1;32m   1180\u001b[0m     join_names\u001b[38;5;241m.\u001b[39mappend(lk)\n\u001b[1;32m   1181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1182\u001b[0m     \u001b[38;5;66;03m# work-around for merge_asof(left_index=True)\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[38;5;241m.\u001b[39mget_level_values(key)  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[38;5;241m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[38;5;66;03m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m values\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Country'"
     ]
    }
   ],
   "source": [
    "merged_df = pd.merge(pop_df, obesity_df, on='Country')\n",
    "merged_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb70ebd1",
   "metadata": {},
   "source": [
    "Task\n",
    "\n",
    "In this task, you'll be using two CSVs from the CIA's world factbook dataset. The file data/c2119.csv maps country names to population. The file data/c2228.csv maps country names to adult obesity rates.\n",
    "\n",
    "Your task is to fill out the analyze(factbook_pop, factbook_obesity) function in analyze.py. This function should:\n",
    "\n",
    "    Read the CSV files (from the two parameter path strings) into a dataframe with Country, Population and Obesity Rate columns\n",
    "    Select countries with obesity rates higher than 20 percent and populations larger than 10,000,000 (107)\n",
    "    Sort the data by Obesity Rate descending\n",
    "    Select the top 10 countries\n",
    "    Index the result from 1-10\n",
    "    Return the dataframe.\n",
    "\n",
    "The expected result (available in data/result.csv) is:\n",
    "\n",
    "           Country  Population  Obesity Rate\n",
    "1            Egypt    88487396          33.1\n",
    "2    United States   321368864          33.0\n",
    "3     Saudi Arabia    27752316          33.0\n",
    "4   Czech Republic    10644842          32.7\n",
    "5           Mexico   121736809          32.1\n",
    "6     South Africa    53675563          31.3\n",
    "7        Venezuela    29275460          30.3\n",
    "8        Argentina    43431886          29.7\n",
    "9            Chile    17508260          29.4\n",
    "10          Turkey    79414269          27.8\n",
    "\n",
    "Notes\n",
    "\n",
    "Paths to CSVs are always relative to the current directory, so you don't need to worry about handling special cases.\n",
    "\n",
    "Your code will be tested on submission with random values to ensure the result wasn't hardcoded.\n",
    "\n",
    "Note that Pandas' testing library offers excellent diffs upon test failure but uses the somewhat confusing left and right names rather than actual and expected. Keep in mind that left == actual and right == expected. The call will be pd.testing.assert_frame_equal(actual, expected) throughout the challenge.\n",
    "Rubric\n",
    "\n",
    "The solution will be evaluated mainly on correctness but use of idiomatic, maintainable Pandas code is taken into consideration as well.\n",
    "Resources\n",
    "\n",
    "You may consult Pandas and Python documentation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a32850d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze(factbook_pop: str, factbook_obesity: str) -> pd.DataFrame:\n",
    "    \n",
    "   #read files  \n",
    "  factbook_pop = pd.read_csv(\"data/c2119.csv\")\n",
    "  factbook_obesity = pd.read_csv(\"data/c2228.csv\")\n",
    "  \n",
    "  #rename columns\n",
    "  factbook_pop.rename(columns={'Pos': 'Index', 'Name': 'Country', 'Value': 'Population'}, inplace=True)\n",
    "  factbook_obesity.rename(columns={'Pos': 'Index', 'Name': 'Country', 'Value': 'Obesity Rate'}, inplace=True)\n",
    "  \n",
    "  #drop unnecessary column \n",
    "  factbook_pop.drop(columns=['Index'], inplace=True)\n",
    "  factbook_obesity.drop(columns=['Index'], inplace=True)\n",
    "  \n",
    "  #merge the dfs by country\n",
    "  merged_df = pd.merge(factbook_pop, factbook_obesity, on='Country')\n",
    "  \n",
    "  #filter the merged dfs \n",
    "  filtered_df = merged_df[(merged_df['Obesity Rate'] > 20) & (merged_df['Population'] > 10000000)]\n",
    "  \n",
    "  #soft the filtered_df\n",
    "  sorted_df = filtered_df.sort_values(by='Obesity Rate', ascending=False)\n",
    "  \n",
    "  #sort the top 10 countries\n",
    "  top_10_df = sorted_df.head(10)\n",
    "  \n",
    "  #index the result from 1-10\n",
    "  top_10_df.index = range(1, 11)\n",
    "    \n",
    "    \n",
    "  return top_10_df\n",
    "  pass \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa44a3",
   "metadata": {},
   "source": [
    "Task\n",
    "\n",
    "In this challenge, you'll write Pandas code to report on the attention.csv dataset. Take a moment to familiarize yourself with the dataset.\n",
    "\n",
    "The three queries will be:\n",
    "\n",
    "    Report how many times it is better to focus than to divide one's attention based on the average scores in the dataset. Return the resulting ratio.\n",
    "    Report the solutions id with the highest average score.\n",
    "    Report the top 10 subjects ranked by the score in descending order. If there are ties in the scores, the subjects should be sorted by subject ID in ascending order. Reset indexes before returning the report.\n",
    "    Note: beware that a subject can appear more than once in the data.\n",
    "\n",
    "See the function documentation and test cases for further details.\n",
    "Rubric\n",
    "\n",
    "Your code will be evaluated on correctness foremost, established by passing the submission test cases. We're looking for clean, idiomatic Pandas and Python code among passing solutions.\n",
    "Resources\n",
    "\n",
    "You may use Python and Pandas documentation as you solve the challenge.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a97645fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def how_many_times_better_is_focused(df: pd.DataFrame) -> float:\n",
    "    \"\"\" Returns how many times better it is to focus than to divide one's attention, based on the average scores (returns the resulting ratio).\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    focus_times = len(df[df['attention'] == 'focused'])\n",
    "    divide_times = len(df[df['attention'] == 'divided'])\n",
    "    n_times = focus_times / divide_times \n",
    "    \n",
    "    len(df[df['attention'] == 'focused'])\n",
    "   \n",
    "#old\n",
    "#focus_times = len(df[df['attention'] > df['divided']])\n",
    "    \n",
    "    focus_times = df[df['attention'] == 'focused'].groupby('attention').size().get('focused', 0)\n",
    "    divide_times = df[df['attention'] == 'divided'].groupby('attention').size().get('divided', 0)\n",
    "\n",
    "    \n",
    "    return n_times\n",
    " #if divide_count != 0 else float('inf')\n",
    "\n",
    "def highest_average_solutions(df: pd.DataFrame) -> int:\n",
    "    \"\"\" Returns the solutions id with the highest average score \"\"\"\n",
    "    \n",
    "    \n",
    "    solution_id = df.groupby('solutions')['score'].mean().idxmax()\n",
    "    \n",
    "    \n",
    "    return solution_id\n",
    "\n",
    "\n",
    "def top_10_scoring_subjects(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "    \n",
    "      df.sort_values(by=['score','subject'],ascending=[False, True]).head(10).reset_index(drop=True)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    sorted_df = df.sort_values(by=['score', 'subject'], ascending=[False, True])\n",
    "    top_10_df = sorted_df.head(10).reset_index(drop=True)\n",
    "    top_10_df = df\n",
    "    \"\"\" Returns df of top 10 subjects ranked by score, descending,\n",
    "        with ties broken by subject id ascending, index reset:\n",
    "   \n",
    "\n",
    "   \n",
    "       subject     score\n",
    "    0       12  8.333333\n",
    "    1       14  7.666667\n",
    "    2       15  7.666667\n",
    "    3       16  7.000000\n",
    "    4       18  7.000000\n",
    "    5        8  6.666667\n",
    "    6       13  6.666667\n",
    "    7       17  6.666667\n",
    "    8        4  5.666667\n",
    "    9        5  5.666667\n",
    "    \"\"\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0abeab87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def analyze_attention_scores(df):\n",
    "    # Query 1: Calculate how many times it is better to focus than to divide attention\n",
    "    focus_count = len(df[df['Focus'] > df['Divided Attention']])\n",
    "    divide_count = len(df[df['Divided Attention'] > df['Focus']])\n",
    "    better_focus_to_divide_ratio = focus_count / divide_count if divide_count != 0 else float('inf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d580f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "def how_many_times_better_is_focused(df: pd.DataFrame) -> float:\n",
    "    \"\"\" Returns how many times better it is to focus than to divide one's attention, based on the average scores (returns the resulting ratio).\n",
    "    \"\"\"\n",
    "    focus_times = df[df['attention'] == 'focused']['score'].mean()\n",
    "    divide_times = df[df['attention'] == 'divided']['score'].mean()\n",
    "    n_times = focus_times / divide_times \n",
    "    \n",
    "    return n_times\n",
    "\n",
    "\n",
    "def highest_average_solutions(df: pd.DataFrame) -> int:\n",
    "    \"\"\" Returns the solutions id with the highest average score \"\"\"\n",
    "    \n",
    "    solution_id = df.groupby('solutions')['score'].mean().idxmax()\n",
    "    \n",
    "    return solution_id\n",
    "\n",
    "\n",
    "def top_10_scoring_subjects(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \n",
    "  sorted_df = df.sort_values(by=['score','subject'], ascending=[False, True])\n",
    "  top_10_df = sorted_df.head(10).reset_index(drop=True)\n",
    "  top_10_df = df\n",
    "    \n",
    "sorted_df = df.sort_values(by=['score', 'subject'], ascending=[False, True])\n",
    "top_10_df = sorted_df.head(10).reset_index(drop=True)\n",
    "    \n",
    "\"\"\" Returns df of top 10 subjects ranked by score, descending,\n",
    "        with ties broken by subject id ascending, index reset:\n",
    "        \n",
    "       subject     score\n",
    "    0       12  8.333333\n",
    "    1       14  7.666667\n",
    "    2       15  7.666667\n",
    "    3       16  7.000000\n",
    "    4       18  7.000000\n",
    "    5        8  6.666667\n",
    "    6       13  6.666667\n",
    "    7       17  6.666667\n",
    "    8        4  5.666667\n",
    "    9        5  5.666667\n",
    "  \"\"\"\n",
    "  \n",
    "  \n",
    "return df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
