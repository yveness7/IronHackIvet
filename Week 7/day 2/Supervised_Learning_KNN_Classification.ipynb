{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2aeb1073",
   "metadata": {},
   "source": [
    "# KNN Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55209572",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix,  ConfusionMatrixDisplay\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb2169af",
   "metadata": {},
   "outputs": [],
   "source": [
    "TT_SPLIT = 0.2     # ratio train/test size\n",
    "RAND_STATE = 123   # specifies a sampling for repeatable results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6df81a27",
   "metadata": {},
   "source": [
    "<b>load classification sample datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6f73c81b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "## classification data sets\n",
    "X, y= datasets.load_breast_cancer(return_X_y=True,as_frame=True) # load the X,y data as dataframes\n",
    "#X, y= datasets.load_iris(return_X_y=True,as_frame=True)\n",
    "#X, y= datasets.load_wine(return_X_y=True,as_frame=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8284418",
   "metadata": {},
   "source": [
    "Information about the [breast-cancer](https://scikit-learn.org/stable/datasets/toy_dataset.html#breast-cancer-dataset) data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09afd18c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "      <td>569.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>14.127292</td>\n",
       "      <td>19.289649</td>\n",
       "      <td>91.969033</td>\n",
       "      <td>654.889104</td>\n",
       "      <td>0.096360</td>\n",
       "      <td>0.104341</td>\n",
       "      <td>0.088799</td>\n",
       "      <td>0.048919</td>\n",
       "      <td>0.181162</td>\n",
       "      <td>0.062798</td>\n",
       "      <td>...</td>\n",
       "      <td>16.269190</td>\n",
       "      <td>25.677223</td>\n",
       "      <td>107.261213</td>\n",
       "      <td>880.583128</td>\n",
       "      <td>0.132369</td>\n",
       "      <td>0.254265</td>\n",
       "      <td>0.272188</td>\n",
       "      <td>0.114606</td>\n",
       "      <td>0.290076</td>\n",
       "      <td>0.083946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.524049</td>\n",
       "      <td>4.301036</td>\n",
       "      <td>24.298981</td>\n",
       "      <td>351.914129</td>\n",
       "      <td>0.014064</td>\n",
       "      <td>0.052813</td>\n",
       "      <td>0.079720</td>\n",
       "      <td>0.038803</td>\n",
       "      <td>0.027414</td>\n",
       "      <td>0.007060</td>\n",
       "      <td>...</td>\n",
       "      <td>4.833242</td>\n",
       "      <td>6.146258</td>\n",
       "      <td>33.602542</td>\n",
       "      <td>569.356993</td>\n",
       "      <td>0.022832</td>\n",
       "      <td>0.157336</td>\n",
       "      <td>0.208624</td>\n",
       "      <td>0.065732</td>\n",
       "      <td>0.061867</td>\n",
       "      <td>0.018061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>6.981000</td>\n",
       "      <td>9.710000</td>\n",
       "      <td>43.790000</td>\n",
       "      <td>143.500000</td>\n",
       "      <td>0.052630</td>\n",
       "      <td>0.019380</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.106000</td>\n",
       "      <td>0.049960</td>\n",
       "      <td>...</td>\n",
       "      <td>7.930000</td>\n",
       "      <td>12.020000</td>\n",
       "      <td>50.410000</td>\n",
       "      <td>185.200000</td>\n",
       "      <td>0.071170</td>\n",
       "      <td>0.027290</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.156500</td>\n",
       "      <td>0.055040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>11.700000</td>\n",
       "      <td>16.170000</td>\n",
       "      <td>75.170000</td>\n",
       "      <td>420.300000</td>\n",
       "      <td>0.086370</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.029560</td>\n",
       "      <td>0.020310</td>\n",
       "      <td>0.161900</td>\n",
       "      <td>0.057700</td>\n",
       "      <td>...</td>\n",
       "      <td>13.010000</td>\n",
       "      <td>21.080000</td>\n",
       "      <td>84.110000</td>\n",
       "      <td>515.300000</td>\n",
       "      <td>0.116600</td>\n",
       "      <td>0.147200</td>\n",
       "      <td>0.114500</td>\n",
       "      <td>0.064930</td>\n",
       "      <td>0.250400</td>\n",
       "      <td>0.071460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>13.370000</td>\n",
       "      <td>18.840000</td>\n",
       "      <td>86.240000</td>\n",
       "      <td>551.100000</td>\n",
       "      <td>0.095870</td>\n",
       "      <td>0.092630</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>0.033500</td>\n",
       "      <td>0.179200</td>\n",
       "      <td>0.061540</td>\n",
       "      <td>...</td>\n",
       "      <td>14.970000</td>\n",
       "      <td>25.410000</td>\n",
       "      <td>97.660000</td>\n",
       "      <td>686.500000</td>\n",
       "      <td>0.131300</td>\n",
       "      <td>0.211900</td>\n",
       "      <td>0.226700</td>\n",
       "      <td>0.099930</td>\n",
       "      <td>0.282200</td>\n",
       "      <td>0.080040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>15.780000</td>\n",
       "      <td>21.800000</td>\n",
       "      <td>104.100000</td>\n",
       "      <td>782.700000</td>\n",
       "      <td>0.105300</td>\n",
       "      <td>0.130400</td>\n",
       "      <td>0.130700</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.195700</td>\n",
       "      <td>0.066120</td>\n",
       "      <td>...</td>\n",
       "      <td>18.790000</td>\n",
       "      <td>29.720000</td>\n",
       "      <td>125.400000</td>\n",
       "      <td>1084.000000</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.339100</td>\n",
       "      <td>0.382900</td>\n",
       "      <td>0.161400</td>\n",
       "      <td>0.317900</td>\n",
       "      <td>0.092080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>28.110000</td>\n",
       "      <td>39.280000</td>\n",
       "      <td>188.500000</td>\n",
       "      <td>2501.000000</td>\n",
       "      <td>0.163400</td>\n",
       "      <td>0.345400</td>\n",
       "      <td>0.426800</td>\n",
       "      <td>0.201200</td>\n",
       "      <td>0.304000</td>\n",
       "      <td>0.097440</td>\n",
       "      <td>...</td>\n",
       "      <td>36.040000</td>\n",
       "      <td>49.540000</td>\n",
       "      <td>251.200000</td>\n",
       "      <td>4254.000000</td>\n",
       "      <td>0.222600</td>\n",
       "      <td>1.058000</td>\n",
       "      <td>1.252000</td>\n",
       "      <td>0.291000</td>\n",
       "      <td>0.663800</td>\n",
       "      <td>0.207500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       mean radius  mean texture  mean perimeter    mean area  \\\n",
       "count   569.000000    569.000000      569.000000   569.000000   \n",
       "mean     14.127292     19.289649       91.969033   654.889104   \n",
       "std       3.524049      4.301036       24.298981   351.914129   \n",
       "min       6.981000      9.710000       43.790000   143.500000   \n",
       "25%      11.700000     16.170000       75.170000   420.300000   \n",
       "50%      13.370000     18.840000       86.240000   551.100000   \n",
       "75%      15.780000     21.800000      104.100000   782.700000   \n",
       "max      28.110000     39.280000      188.500000  2501.000000   \n",
       "\n",
       "       mean smoothness  mean compactness  mean concavity  mean concave points  \\\n",
       "count       569.000000        569.000000      569.000000           569.000000   \n",
       "mean          0.096360          0.104341        0.088799             0.048919   \n",
       "std           0.014064          0.052813        0.079720             0.038803   \n",
       "min           0.052630          0.019380        0.000000             0.000000   \n",
       "25%           0.086370          0.064920        0.029560             0.020310   \n",
       "50%           0.095870          0.092630        0.061540             0.033500   \n",
       "75%           0.105300          0.130400        0.130700             0.074000   \n",
       "max           0.163400          0.345400        0.426800             0.201200   \n",
       "\n",
       "       mean symmetry  mean fractal dimension  ...  worst radius  \\\n",
       "count     569.000000              569.000000  ...    569.000000   \n",
       "mean        0.181162                0.062798  ...     16.269190   \n",
       "std         0.027414                0.007060  ...      4.833242   \n",
       "min         0.106000                0.049960  ...      7.930000   \n",
       "25%         0.161900                0.057700  ...     13.010000   \n",
       "50%         0.179200                0.061540  ...     14.970000   \n",
       "75%         0.195700                0.066120  ...     18.790000   \n",
       "max         0.304000                0.097440  ...     36.040000   \n",
       "\n",
       "       worst texture  worst perimeter   worst area  worst smoothness  \\\n",
       "count     569.000000       569.000000   569.000000        569.000000   \n",
       "mean       25.677223       107.261213   880.583128          0.132369   \n",
       "std         6.146258        33.602542   569.356993          0.022832   \n",
       "min        12.020000        50.410000   185.200000          0.071170   \n",
       "25%        21.080000        84.110000   515.300000          0.116600   \n",
       "50%        25.410000        97.660000   686.500000          0.131300   \n",
       "75%        29.720000       125.400000  1084.000000          0.146000   \n",
       "max        49.540000       251.200000  4254.000000          0.222600   \n",
       "\n",
       "       worst compactness  worst concavity  worst concave points  \\\n",
       "count         569.000000       569.000000            569.000000   \n",
       "mean            0.254265         0.272188              0.114606   \n",
       "std             0.157336         0.208624              0.065732   \n",
       "min             0.027290         0.000000              0.000000   \n",
       "25%             0.147200         0.114500              0.064930   \n",
       "50%             0.211900         0.226700              0.099930   \n",
       "75%             0.339100         0.382900              0.161400   \n",
       "max             1.058000         1.252000              0.291000   \n",
       "\n",
       "       worst symmetry  worst fractal dimension  \n",
       "count      569.000000               569.000000  \n",
       "mean         0.290076                 0.083946  \n",
       "std          0.061867                 0.018061  \n",
       "min          0.156500                 0.055040  \n",
       "25%          0.250400                 0.071460  \n",
       "50%          0.282200                 0.080040  \n",
       "75%          0.317900                 0.092080  \n",
       "max          0.663800                 0.207500  \n",
       "\n",
       "[8 rows x 30 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# input variables\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "99a40810",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = y.apply( lambda x : 1 if x==0 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1b5b97f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    357\n",
       "1    212\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# target variable is malignant or benign (binary label).\n",
    "# let's check the distribution of labels\n",
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c162590",
   "metadata": {},
   "source": [
    "### train/test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d66c85b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test=train_test_split(X, y, test_size=TT_SPLIT,random_state=RAND_STATE) # splitting the data into train and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90451e49",
   "metadata": {},
   "source": [
    "### Knn_Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cd2beb4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>11.250</td>\n",
       "      <td>14.78</td>\n",
       "      <td>71.38</td>\n",
       "      <td>390.0</td>\n",
       "      <td>0.08306</td>\n",
       "      <td>0.04458</td>\n",
       "      <td>0.000974</td>\n",
       "      <td>0.002941</td>\n",
       "      <td>0.1773</td>\n",
       "      <td>0.06081</td>\n",
       "      <td>...</td>\n",
       "      <td>12.760</td>\n",
       "      <td>22.06</td>\n",
       "      <td>82.08</td>\n",
       "      <td>492.7</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.09794</td>\n",
       "      <td>0.005518</td>\n",
       "      <td>0.016670</td>\n",
       "      <td>0.2815</td>\n",
       "      <td>0.07418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>9.742</td>\n",
       "      <td>15.67</td>\n",
       "      <td>61.50</td>\n",
       "      <td>289.9</td>\n",
       "      <td>0.09037</td>\n",
       "      <td>0.04689</td>\n",
       "      <td>0.011030</td>\n",
       "      <td>0.014070</td>\n",
       "      <td>0.2081</td>\n",
       "      <td>0.06312</td>\n",
       "      <td>...</td>\n",
       "      <td>10.750</td>\n",
       "      <td>20.88</td>\n",
       "      <td>68.09</td>\n",
       "      <td>355.2</td>\n",
       "      <td>0.14670</td>\n",
       "      <td>0.09370</td>\n",
       "      <td>0.040430</td>\n",
       "      <td>0.051590</td>\n",
       "      <td>0.2841</td>\n",
       "      <td>0.08175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>17.540</td>\n",
       "      <td>19.32</td>\n",
       "      <td>115.10</td>\n",
       "      <td>951.6</td>\n",
       "      <td>0.08968</td>\n",
       "      <td>0.11980</td>\n",
       "      <td>0.103600</td>\n",
       "      <td>0.074880</td>\n",
       "      <td>0.1506</td>\n",
       "      <td>0.05491</td>\n",
       "      <td>...</td>\n",
       "      <td>20.420</td>\n",
       "      <td>25.84</td>\n",
       "      <td>139.50</td>\n",
       "      <td>1239.0</td>\n",
       "      <td>0.13810</td>\n",
       "      <td>0.34200</td>\n",
       "      <td>0.350800</td>\n",
       "      <td>0.193900</td>\n",
       "      <td>0.2928</td>\n",
       "      <td>0.07867</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>13.010</td>\n",
       "      <td>22.22</td>\n",
       "      <td>82.01</td>\n",
       "      <td>526.4</td>\n",
       "      <td>0.06251</td>\n",
       "      <td>0.01938</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>0.001852</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.05234</td>\n",
       "      <td>...</td>\n",
       "      <td>14.000</td>\n",
       "      <td>29.02</td>\n",
       "      <td>88.18</td>\n",
       "      <td>608.8</td>\n",
       "      <td>0.08125</td>\n",
       "      <td>0.03432</td>\n",
       "      <td>0.007977</td>\n",
       "      <td>0.009259</td>\n",
       "      <td>0.2295</td>\n",
       "      <td>0.05843</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>18.460</td>\n",
       "      <td>18.52</td>\n",
       "      <td>121.10</td>\n",
       "      <td>1075.0</td>\n",
       "      <td>0.09874</td>\n",
       "      <td>0.10530</td>\n",
       "      <td>0.133500</td>\n",
       "      <td>0.087950</td>\n",
       "      <td>0.2132</td>\n",
       "      <td>0.06022</td>\n",
       "      <td>...</td>\n",
       "      <td>22.930</td>\n",
       "      <td>27.68</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.20890</td>\n",
       "      <td>0.315700</td>\n",
       "      <td>0.164200</td>\n",
       "      <td>0.3695</td>\n",
       "      <td>0.08579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>12.810</td>\n",
       "      <td>13.06</td>\n",
       "      <td>81.29</td>\n",
       "      <td>508.8</td>\n",
       "      <td>0.08739</td>\n",
       "      <td>0.03774</td>\n",
       "      <td>0.009193</td>\n",
       "      <td>0.013300</td>\n",
       "      <td>0.1466</td>\n",
       "      <td>0.06133</td>\n",
       "      <td>...</td>\n",
       "      <td>13.630</td>\n",
       "      <td>16.15</td>\n",
       "      <td>86.70</td>\n",
       "      <td>570.7</td>\n",
       "      <td>0.11620</td>\n",
       "      <td>0.05445</td>\n",
       "      <td>0.027580</td>\n",
       "      <td>0.039900</td>\n",
       "      <td>0.1783</td>\n",
       "      <td>0.07319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>9.720</td>\n",
       "      <td>18.22</td>\n",
       "      <td>60.73</td>\n",
       "      <td>288.1</td>\n",
       "      <td>0.06950</td>\n",
       "      <td>0.02344</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1653</td>\n",
       "      <td>0.06447</td>\n",
       "      <td>...</td>\n",
       "      <td>9.968</td>\n",
       "      <td>20.83</td>\n",
       "      <td>62.25</td>\n",
       "      <td>303.8</td>\n",
       "      <td>0.07117</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1909</td>\n",
       "      <td>0.06559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>246</th>\n",
       "      <td>13.200</td>\n",
       "      <td>17.43</td>\n",
       "      <td>84.13</td>\n",
       "      <td>541.6</td>\n",
       "      <td>0.07215</td>\n",
       "      <td>0.04524</td>\n",
       "      <td>0.043360</td>\n",
       "      <td>0.011050</td>\n",
       "      <td>0.1487</td>\n",
       "      <td>0.05635</td>\n",
       "      <td>...</td>\n",
       "      <td>13.940</td>\n",
       "      <td>27.82</td>\n",
       "      <td>88.28</td>\n",
       "      <td>602.0</td>\n",
       "      <td>0.11010</td>\n",
       "      <td>0.15080</td>\n",
       "      <td>0.229800</td>\n",
       "      <td>0.049700</td>\n",
       "      <td>0.2767</td>\n",
       "      <td>0.07198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>11.840</td>\n",
       "      <td>18.94</td>\n",
       "      <td>75.51</td>\n",
       "      <td>428.0</td>\n",
       "      <td>0.08871</td>\n",
       "      <td>0.06900</td>\n",
       "      <td>0.026690</td>\n",
       "      <td>0.013930</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.06057</td>\n",
       "      <td>...</td>\n",
       "      <td>13.300</td>\n",
       "      <td>24.99</td>\n",
       "      <td>85.22</td>\n",
       "      <td>546.3</td>\n",
       "      <td>0.12800</td>\n",
       "      <td>0.18800</td>\n",
       "      <td>0.147100</td>\n",
       "      <td>0.069130</td>\n",
       "      <td>0.2535</td>\n",
       "      <td>0.07993</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>17.200</td>\n",
       "      <td>24.52</td>\n",
       "      <td>114.20</td>\n",
       "      <td>929.4</td>\n",
       "      <td>0.10710</td>\n",
       "      <td>0.18300</td>\n",
       "      <td>0.169200</td>\n",
       "      <td>0.079440</td>\n",
       "      <td>0.1927</td>\n",
       "      <td>0.06487</td>\n",
       "      <td>...</td>\n",
       "      <td>23.320</td>\n",
       "      <td>33.82</td>\n",
       "      <td>151.60</td>\n",
       "      <td>1681.0</td>\n",
       "      <td>0.15850</td>\n",
       "      <td>0.73940</td>\n",
       "      <td>0.656600</td>\n",
       "      <td>0.189900</td>\n",
       "      <td>0.3313</td>\n",
       "      <td>0.13390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>114 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "333       11.250         14.78           71.38      390.0          0.08306   \n",
       "273        9.742         15.67           61.50      289.9          0.09037   \n",
       "201       17.540         19.32          115.10      951.6          0.08968   \n",
       "178       13.010         22.22           82.01      526.4          0.06251   \n",
       "85        18.460         18.52          121.10     1075.0          0.09874   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "179       12.810         13.06           81.29      508.8          0.08739   \n",
       "192        9.720         18.22           60.73      288.1          0.06950   \n",
       "246       13.200         17.43           84.13      541.6          0.07215   \n",
       "211       11.840         18.94           75.51      428.0          0.08871   \n",
       "72        17.200         24.52          114.20      929.4          0.10710   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "333           0.04458        0.000974             0.002941         0.1773   \n",
       "273           0.04689        0.011030             0.014070         0.2081   \n",
       "201           0.11980        0.103600             0.074880         0.1506   \n",
       "178           0.01938        0.001595             0.001852         0.1395   \n",
       "85            0.10530        0.133500             0.087950         0.2132   \n",
       "..                ...             ...                  ...            ...   \n",
       "179           0.03774        0.009193             0.013300         0.1466   \n",
       "192           0.02344        0.000000             0.000000         0.1653   \n",
       "246           0.04524        0.043360             0.011050         0.1487   \n",
       "211           0.06900        0.026690             0.013930         0.1533   \n",
       "72            0.18300        0.169200             0.079440         0.1927   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "333                 0.06081  ...        12.760          22.06   \n",
       "273                 0.06312  ...        10.750          20.88   \n",
       "201                 0.05491  ...        20.420          25.84   \n",
       "178                 0.05234  ...        14.000          29.02   \n",
       "85                  0.06022  ...        22.930          27.68   \n",
       "..                      ...  ...           ...            ...   \n",
       "179                 0.06133  ...        13.630          16.15   \n",
       "192                 0.06447  ...         9.968          20.83   \n",
       "246                 0.05635  ...        13.940          27.82   \n",
       "211                 0.06057  ...        13.300          24.99   \n",
       "72                  0.06487  ...        23.320          33.82   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "333            82.08       492.7           0.11660            0.09794   \n",
       "273            68.09       355.2           0.14670            0.09370   \n",
       "201           139.50      1239.0           0.13810            0.34200   \n",
       "178            88.18       608.8           0.08125            0.03432   \n",
       "85            152.20      1603.0           0.13980            0.20890   \n",
       "..               ...         ...               ...                ...   \n",
       "179            86.70       570.7           0.11620            0.05445   \n",
       "192            62.25       303.8           0.07117            0.02729   \n",
       "246            88.28       602.0           0.11010            0.15080   \n",
       "211            85.22       546.3           0.12800            0.18800   \n",
       "72            151.60      1681.0           0.15850            0.73940   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "333         0.005518              0.016670          0.2815   \n",
       "273         0.040430              0.051590          0.2841   \n",
       "201         0.350800              0.193900          0.2928   \n",
       "178         0.007977              0.009259          0.2295   \n",
       "85          0.315700              0.164200          0.3695   \n",
       "..               ...                   ...             ...   \n",
       "179         0.027580              0.039900          0.1783   \n",
       "192         0.000000              0.000000          0.1909   \n",
       "246         0.229800              0.049700          0.2767   \n",
       "211         0.147100              0.069130          0.2535   \n",
       "72          0.656600              0.189900          0.3313   \n",
       "\n",
       "     worst fractal dimension  \n",
       "333                  0.07418  \n",
       "273                  0.08175  \n",
       "201                  0.07867  \n",
       "178                  0.05843  \n",
       "85                   0.08579  \n",
       "..                       ...  \n",
       "179                  0.07319  \n",
       "192                  0.06559  \n",
       "246                  0.07198  \n",
       "211                  0.07993  \n",
       "72                   0.13390  \n",
       "\n",
       "[114 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e91eb60c",
   "metadata": {},
   "source": [
    "## scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "51689d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler= MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "X_train_scaled = scaler.transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d0e6e40f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Error_metric</th>\n",
       "      <th>Train</th>\n",
       "      <th>Test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Accuracy</td>\n",
       "      <td>0.975824</td>\n",
       "      <td>0.982456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Precision</td>\n",
       "      <td>0.987805</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Recall</td>\n",
       "      <td>0.947368</td>\n",
       "      <td>0.951220</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Error_metric     Train      Test\n",
       "0     Accuracy  0.975824  0.982456\n",
       "1    Precision  0.987805  1.000000\n",
       "2       Recall  0.947368  0.951220"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = KNeighborsClassifier(n_neighbors=5,weights='uniform') # declare we're using knn classification model\n",
    "model.fit(X_train_scaled, y_train) # train model\n",
    "y_pred = model.predict(X_test_scaled) # predict test\n",
    "y_pred_train=model.predict(X_train_scaled) # predict train (for sanity checks)\n",
    "\n",
    "performance_log = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train),\n",
    "                                         precision_score(y_train, y_pred_train),\n",
    "                                         recall_score(y_train, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred),\n",
    "                                        precision_score(y_test, y_pred),\n",
    "                                        recall_score(y_test, y_pred)]})\n",
    "\n",
    "display(performance_log)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9cef5b11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0,\n",
       "       1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1,\n",
       "       0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e1df6d8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, 1])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3d9e04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "333    0\n",
       "273    0\n",
       "201    1\n",
       "178    0\n",
       "85     1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1870e49b",
   "metadata": {},
   "source": [
    "### Confusion matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b9dbed7",
   "metadata": {},
   "source": [
    "Confusion matrices allow us to visualize how the model performs by showing how the predicted labels compare with the true (test) labels.\n",
    "The false positives (upper right corners) and false negatives (lower left corners) impact the precision and recall scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0460e8ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x7f756c860410>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm = confusion_matrix(y_test, y_pred, labels= model.classes_)\n",
    "disp = ConfusionMatrixDisplay(cm)\n",
    "disp.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a1be840",
   "metadata": {},
   "source": [
    "Train results: 19 predictions where the model missed a malignant case and 0 cases where the model predicted cancer where the was none.\n",
    "Test results: 5 predictions where the model misclassified malignant records and 2 cases where the model predicted a cancer where there was none."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64c22712",
   "metadata": {},
   "source": [
    "### Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dddbc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_classification_model(y_train, y_pred_train, y_test, y_pred_test):\n",
    "    \"\"\"\n",
    "    Generates performance metrics and comparisons of labels with their predicted values\n",
    "    :param y_train: training labels\n",
    "    :param y_pred_train: predictions from the model on the training set\n",
    "    :param y_test: test labels\n",
    "    :param y_pred_test: predictions from the model on the test set\n",
    "    :returns: 3 dfs - Accuracy, Precision, and Recall scores, y_train vs. y_pred_train and y_test vs. y_pred_dist\n",
    "    \"\"\"\n",
    "    performance_df = pd.DataFrame({'Error_metric': ['Accuracy','Precision','Recall'],\n",
    "                               'Train': [accuracy_score(y_train, y_pred_train),\n",
    "                                         precision_score(y_train, y_pred_train),\n",
    "                                         recall_score(y_train, y_pred_train)],\n",
    "                               'Test': [accuracy_score(y_test, y_pred_test),\n",
    "                                        precision_score(y_test, y_pred_test),\n",
    "                                        recall_score(y_test, y_pred_test)]})\n",
    "    \n",
    "    pd.options.display.float_format = '{:.2f}'.format\n",
    "\n",
    "    df_train = pd.DataFrame({'Real': y_train, 'Predicted': y_pred_train})\n",
    "    df_test  = pd.DataFrame({'Real': y_test,  'Predicted': y_pred_test})\n",
    "\n",
    "    return performance_df, df_train, df_test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc082e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## calling the function\n",
    "error_metrics_df,y_train_vs_predicted, y_test_vs_predicted =evaluate_classification_model(y_train, y_pred_train,y_test, y_pred)\n",
    "error_metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4d34067",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_vs_predicted # train labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a10e41ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_vs_predicted # test labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80d314da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
